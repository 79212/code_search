{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "This notebook contains materials to parse raw python files into function and docstring pairs, tokenize both function and dosctring into tokens, and split these pairs into train, valid and test set.  \n",
    "\n",
    "*This step is optional, as we provide links to download pre-processed data at various points in the tutorial.  However, you might find it useful to go through these steps in order to understand how the data is prepared.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ast\n",
    "import glob\n",
    "import re\n",
    "from general_utils import apply_parallel, flattenlist\n",
    "\n",
    "import astor\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "EN = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and read  raw python files\n",
    "\n",
    "The first thing we will want to do is to gather python code.  There is an open dataset that Google hosts on [bigquery](https://cloud.google.com/bigquery/) that has code from open source projects on Github.  You can use [bigquery](https://cloud.google.com/bigquery/) to get the python files as a tabular dataset by executing the following SQL query in the bigquery console:\n",
    "\n",
    "```{sql}\n",
    "SELECT \n",
    " max(concat(f.repo_name, ' ', f.path)) as repo_path,\n",
    " c.content\n",
    "FROM `bigquery-public-data.github_repos.files` as f\n",
    "JOIN `bigquery-public-data.github_repos.contents` as c on f.id = c.id\n",
    "JOIN (\n",
    "      --this part of the query makes sure repo is watched at least twice since 2017\n",
    "      SELECT repo FROM(\n",
    "        SELECT \n",
    "          repo.name as repo\n",
    "        FROM `githubarchive.year.2017` WHERE type=\"WatchEvent\"\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "          repo.name as repo\n",
    "        FROM `githubarchive.month.2018*` WHERE type=\"WatchEvent\"\n",
    "        )\n",
    "      GROUP BY 1\n",
    "      HAVING COUNT(*) >= 2\n",
    "      ) as r on f.repo_name = r.repo\n",
    "WHERE \n",
    "  f.path like '%.py' and --with python extension\n",
    "  c.size < 15000 and --get rid of ridiculously long files\n",
    "  REGEXP_CONTAINS(c.content, r'def ') --contains function definition\n",
    "group by c.content\n",
    "```\n",
    "\n",
    "\n",
    "Here is a link to the [SQL Query](https://bigquery.cloud.google.com/savedquery/506213277345:009fa66f301240e5ad9e4006c59a4762) incase it is helpful.  The raw data contains approximate 1.2 million distinct python code files.\n",
    "\n",
    "**To make things easier for this tutorial, the folks at Google have hosted the raw data for this tutorial in the form of 10 part csv files, available at the url: https://storage.googleapis.com/kubeflow-examples/code_search/raw_data/00000000000{i}.csv as illustrated in the below code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fnl/libfnl</td>\n",
       "      <td>src/fnl/nlp/dictionary.py</td>\n",
       "      <td>\"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KivApple/mcu-info-util</td>\n",
       "      <td>mcu_info_util/linker_script.py</td>\n",
       "      <td>from six import iteritems\\n\\n\\ndef generate(op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yelp/pyleus</td>\n",
       "      <td>examples/bandwith_monitoring/bandwith_monitori...</td>\n",
       "      <td>from __future__ import absolute_import, divisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jhuapl-boss/boss-manage</td>\n",
       "      <td>bin/bearer_token.py</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\n# Copyright 2016 The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>djfroofy/beatlounge</td>\n",
       "      <td>bl/orchestra/base.py</td>\n",
       "      <td>from itertools import cycle\\n\\nfrom twisted.py...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nwo                                               path  \\\n",
       "0               fnl/libfnl                          src/fnl/nlp/dictionary.py   \n",
       "1   KivApple/mcu-info-util                     mcu_info_util/linker_script.py   \n",
       "2              Yelp/pyleus  examples/bandwith_monitoring/bandwith_monitori...   \n",
       "3  jhuapl-boss/boss-manage                                bin/bearer_token.py   \n",
       "4      djfroofy/beatlounge                               bl/orchestra/base.py   \n",
       "\n",
       "                                             content  \n",
       "0  \"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...  \n",
       "1  from six import iteritems\\n\\n\\ndef generate(op...  \n",
       "2  from __future__ import absolute_import, divisi...  \n",
       "3  #!/usr/bin/env python3\\n\\n# Copyright 2016 The...  \n",
       "4  from itertools import cycle\\n\\nfrom twisted.py...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a pandas dataframe, and parse out some meta-data\n",
    "\n",
    "df = pd.concat([pd.read_csv(f'https://storage.googleapis.com/kubeflow-examples/code_search/raw_data/00000000000{i}.csv') \\\n",
    "                for i in range(10)])\n",
    "\n",
    "df['nwo'] = df['repo_path'].apply(lambda r: r.split()[0])\n",
    "df['path'] = df['repo_path'].apply(lambda r: r.split()[1])\n",
    "df.drop(columns=['repo_path'], inplace=True)\n",
    "df = df[['nwo', 'path', 'content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241664, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect shape of the raw data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to parse and generate pairs and tokenize\n",
    "\n",
    "Our goal is to parse the python files into (code, docstring) pairs.  Fortunately, the standard library in python comes with the wonderful [ast](https://docs.python.org/3.6/library/ast.html) module which helps us extract code from files as well as extract docstrings.  \n",
    "\n",
    "We also use the [astor](http://astor.readthedocs.io/en/latest/) library to strip the code of comments by doing a round trip of converting the code to an [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree) and then from AST back to code. \n",
    "\n",
    "Because of these robust libraries, we do not have to use regular expressions to parse code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_docstring(text):\n",
    "    \"Apply tokenization using spacy to docstrings.\"\n",
    "    tokens = EN.tokenizer(text)\n",
    "    return [token.text.lower() for token in tokens if not token.is_space]\n",
    "\n",
    "\n",
    "def tokenize_code(text):\n",
    "    \"A very basic procedure for tokenizing code strings.\"\n",
    "    return RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "\n",
    "\n",
    "def get_function_docstring_pairs(blob):\n",
    "    \"Extract (function/method, docstring) pairs from a given code blob.\"\n",
    "    pairs = []\n",
    "    try:\n",
    "        module = ast.parse(blob)\n",
    "        classes = [node for node in module.body if isinstance(node, ast.ClassDef)]\n",
    "        functions = [node for node in module.body if isinstance(node, ast.FunctionDef)]\n",
    "        for _class in classes:\n",
    "            functions.extend([node for node in _class.body if isinstance(node, ast.FunctionDef)])\n",
    "\n",
    "        for f in functions:\n",
    "            source = astor.to_source(f)\n",
    "            docstring = ast.get_docstring(f) if ast.get_docstring(f) else ''\n",
    "            function = source.replace(ast.get_docstring(f, clean=False), '') if docstring else source\n",
    "\n",
    "            pairs.append((f.name,\n",
    "                          f.lineno,\n",
    "                          source,\n",
    "                          ' '.join(tokenize_code(function)),\n",
    "                          ' '.join(tokenize_docstring(docstring.split('\\n\\n')[0]))\n",
    "                         ))\n",
    "    except (AssertionError, MemoryError, SyntaxError, UnicodeEncodeError):\n",
    "        pass\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def get_function_docstring_pairs_list(blob_list):\n",
    "    \"\"\"apply the function `get_function_docstring_pairs` on a list of blobs\"\"\"\n",
    "    return [get_function_docstring_pairs(b) for b in blob_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below convience function `apply_parallel` parses the code in parallel using process based threading.  Adjust the `cpu_cores` parameter accordingly to your system resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 1min 22s, total: 2min 25s\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = flattenlist(apply_parallel(get_function_docstring_pairs_list, df.content.tolist(), cpu_cores=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>content</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fnl/libfnl</td>\n",
       "      <td>src/fnl/nlp/dictionary.py</td>\n",
       "      <td>\"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...</td>\n",
       "      <td>[(__init__, 19, def __init__(self, *leafs, **e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KivApple/mcu-info-util</td>\n",
       "      <td>mcu_info_util/linker_script.py</td>\n",
       "      <td>from six import iteritems\\n\\n\\ndef generate(op...</td>\n",
       "      <td>[(generate, 4, def generate(options, filename=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yelp/pyleus</td>\n",
       "      <td>examples/bandwith_monitoring/bandwith_monitori...</td>\n",
       "      <td>from __future__ import absolute_import, divisi...</td>\n",
       "      <td>[(__init__, 18, def __init__(self, size):\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jhuapl-boss/boss-manage</td>\n",
       "      <td>bin/bearer_token.py</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\n# Copyright 2016 The...</td>\n",
       "      <td>[(request, 46, def request(url, params=None, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>djfroofy/beatlounge</td>\n",
       "      <td>bl/orchestra/base.py</td>\n",
       "      <td>from itertools import cycle\\n\\nfrom twisted.py...</td>\n",
       "      <td>[(schedule, 149, def schedule(time, func, args...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nwo                                               path  \\\n",
       "0               fnl/libfnl                          src/fnl/nlp/dictionary.py   \n",
       "1   KivApple/mcu-info-util                     mcu_info_util/linker_script.py   \n",
       "2              Yelp/pyleus  examples/bandwith_monitoring/bandwith_monitori...   \n",
       "3  jhuapl-boss/boss-manage                                bin/bearer_token.py   \n",
       "4      djfroofy/beatlounge                               bl/orchestra/base.py   \n",
       "\n",
       "                                             content  \\\n",
       "0  \"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...   \n",
       "1  from six import iteritems\\n\\n\\ndef generate(op...   \n",
       "2  from __future__ import absolute_import, divisi...   \n",
       "3  #!/usr/bin/env python3\\n\\n# Copyright 2016 The...   \n",
       "4  from itertools import cycle\\n\\nfrom twisted.py...   \n",
       "\n",
       "                                               pairs  \n",
       "0  [(__init__, 19, def __init__(self, *leafs, **e...  \n",
       "1  [(generate, 4, def generate(options, filename=...  \n",
       "2  [(__init__, 18, def __init__(self, size):\\n   ...  \n",
       "3  [(request, 46, def request(url, params=None, h...  \n",
       "4  [(schedule, 149, def schedule(time, func, args...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(pairs) == df.shape[0], f'Row count mismatch. `df` has {df.shape[0]:,} rows; `pairs` has {len(pairs):,} rows.'\n",
    "df['pairs'] = pairs\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten code, docstring pairs and extract meta-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten (code, docstring) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 25s, sys: 17.6 s, total: 9min 42s\n",
      "Wall time: 9min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# flatten pairs\n",
    "df = df.set_index(['nwo', 'path'])['pairs'].apply(pd.Series).stack()\n",
    "df = df.reset_index()\n",
    "df.columns = ['nwo', 'path', '_', 'pair']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract meta-data and format dataframe.  \n",
    "\n",
    "We have not optimized this code.  Pull requests are welcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 45s, sys: 1.9 s, total: 5min 47s\n",
      "Wall time: 5min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['function_name'] = df['pair'].apply(lambda p: p[0])\n",
    "df['lineno'] = df['pair'].apply(lambda p: p[1])\n",
    "df['original_function'] = df['pair'].apply(lambda p: p[2])\n",
    "df['function_tokens'] = df['pair'].apply(lambda p: p[3])\n",
    "df['docstring_tokens'] = df['pair'].apply(lambda p: p[4])\n",
    "df = df[['nwo', 'path', 'function_name', 'lineno', 'original_function', 'function_tokens', 'docstring_tokens']]\n",
    "df['url'] = df[['nwo', 'path', 'lineno']].apply(lambda x: 'https://github.com/{}/blob/master/{}#L{}'.format(x[0], x[1], x[2]), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove observations where the same function appears more than once\n",
    "df = df.drop_duplicates(['original_function', 'function_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start to see how the data looks, the function tokens and docstring tokens are what will be fed downstream into the models.  The other information is important for diagnostics and bookeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>lineno</th>\n",
       "      <th>original_function</th>\n",
       "      <th>function_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fnl/libfnl</td>\n",
       "      <td>src/fnl/nlp/dictionary.py</td>\n",
       "      <td>__init__</td>\n",
       "      <td>19</td>\n",
       "      <td>def __init__(self, *leafs, **edges):\\n    self...</td>\n",
       "      <td>def __init__ self leafs edges self edges edges...</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fnl/libfnl</td>\n",
       "      <td>src/fnl/nlp/dictionary.py</td>\n",
       "      <td>__eq__</td>\n",
       "      <td>23</td>\n",
       "      <td>def __eq__(self, other):\\n    if isinstance(ot...</td>\n",
       "      <td>def __eq__ self other if isinstance other Node...</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fnl/libfnl</td>\n",
       "      <td>src/fnl/nlp/dictionary.py</td>\n",
       "      <td>__repr__</td>\n",
       "      <td>29</td>\n",
       "      <td>def __repr__(self):\\n    return 'Node&lt;leafs={}...</td>\n",
       "      <td>def __repr__ self return Node leafs edges form...</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fnl/libfnl</td>\n",
       "      <td>src/fnl/nlp/dictionary.py</td>\n",
       "      <td>createOrGet</td>\n",
       "      <td>32</td>\n",
       "      <td>def createOrGet(self, token):\\n    \"\"\"\\n\\t\\tCr...</td>\n",
       "      <td>def createOrGet self token if token in self ed...</td>\n",
       "      <td>create or get the node pointed to by ` token `...</td>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fnl/libfnl</td>\n",
       "      <td>src/fnl/nlp/dictionary.py</td>\n",
       "      <td>setLeaf</td>\n",
       "      <td>47</td>\n",
       "      <td>def setLeaf(self, key, order):\\n    \"\"\"\\n\\t\\tS...</td>\n",
       "      <td>def setLeaf self key order self leafs append o...</td>\n",
       "      <td>store the ` key ` as a leaf of this node at po...</td>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          nwo                       path function_name  lineno  \\\n",
       "0  fnl/libfnl  src/fnl/nlp/dictionary.py      __init__      19   \n",
       "1  fnl/libfnl  src/fnl/nlp/dictionary.py        __eq__      23   \n",
       "2  fnl/libfnl  src/fnl/nlp/dictionary.py      __repr__      29   \n",
       "3  fnl/libfnl  src/fnl/nlp/dictionary.py   createOrGet      32   \n",
       "4  fnl/libfnl  src/fnl/nlp/dictionary.py       setLeaf      47   \n",
       "\n",
       "                                   original_function  \\\n",
       "0  def __init__(self, *leafs, **edges):\\n    self...   \n",
       "1  def __eq__(self, other):\\n    if isinstance(ot...   \n",
       "2  def __repr__(self):\\n    return 'Node<leafs={}...   \n",
       "3  def createOrGet(self, token):\\n    \"\"\"\\n\\t\\tCr...   \n",
       "4  def setLeaf(self, key, order):\\n    \"\"\"\\n\\t\\tS...   \n",
       "\n",
       "                                     function_tokens  \\\n",
       "0  def __init__ self leafs edges self edges edges...   \n",
       "1  def __eq__ self other if isinstance other Node...   \n",
       "2  def __repr__ self return Node leafs edges form...   \n",
       "3  def createOrGet self token if token in self ed...   \n",
       "4  def setLeaf self key order self leafs append o...   \n",
       "\n",
       "                                    docstring_tokens  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  create or get the node pointed to by ` token `...   \n",
       "4  store the ` key ` as a leaf of this node at po...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://github.com/fnl/libfnl/blob/master/src/...  \n",
       "1  https://github.com/fnl/libfnl/blob/master/src/...  \n",
       "2  https://github.com/fnl/libfnl/blob/master/src/...  \n",
       "3  https://github.com/fnl/libfnl/blob/master/src/...  \n",
       "4  https://github.com/fnl/libfnl/blob/master/src/...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5413927, 8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate function w/o docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate functions w/o docstrings\n",
    "with_docstrings = df[df['docstring_tokens'] != '']\n",
    "without_docstrings = df[df['docstring_tokens'] == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition code by repository to minimize leakage between train, valid & test sets. \n",
    "Rough assumption that each repository has its own style.  We want to avoid having code from the same repository in the training set as well as the validation or holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = with_docstrings.groupby('nwo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# train, valid, test splits\n",
    "train, test = train_test_split(list(grouped), train_size=0.90, shuffle=True)\n",
    "train, valid = train_test_split(train, train_size=0.83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([d for _, d in train]).reset_index(drop=True)\n",
    "valid = pd.concat([d for _, d in valid]).reset_index(drop=True)\n",
    "test = pd.concat([d for _, d in test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set num rows 1,099,566\n",
      "valid set num rows 177,389\n",
      "test set num rows 169,230\n",
      "without docstring rows 3,967,742\n"
     ]
    }
   ],
   "source": [
    "print(f'train set num rows {train.shape[0]:,}')\n",
    "print(f'valid set num rows {valid.shape[0]:,}')\n",
    "print(f'test set num rows {test.shape[0]:,}')\n",
    "print(f'without docstring rows {without_docstrings.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview what the training set looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>lineno</th>\n",
       "      <th>original_function</th>\n",
       "      <th>function_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ralphbean/raptorizemw</td>\n",
       "      <td>examples/tg2-raptorized/tg2raptorized/websetup...</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>8</td>\n",
       "      <td>def bootstrap(command, conf, vars):\\n    \"\"\"Pl...</td>\n",
       "      <td>def bootstrap command conf vars</td>\n",
       "      <td>place any commands to setup tg2raptorized here</td>\n",
       "      <td>https://github.com/ralphbean/raptorizemw/blob/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ralphbean/raptorizemw</td>\n",
       "      <td>examples/tg2-raptorized/tg2raptorized/controll...</td>\n",
       "      <td>document</td>\n",
       "      <td>21</td>\n",
       "      <td>@expose('tg2raptorized.templates.error')\\ndef ...</td>\n",
       "      <td>expose tg2raptorized templates error def docum...</td>\n",
       "      <td>render the error document</td>\n",
       "      <td>https://github.com/ralphbean/raptorizemw/blob/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ralphbean/raptorizemw</td>\n",
       "      <td>examples/tg2-raptorized/tg2raptorized/websetup...</td>\n",
       "      <td>setup_schema</td>\n",
       "      <td>7</td>\n",
       "      <td>def setup_schema(command, conf, vars):\\n    \"\"...</td>\n",
       "      <td>def setup_schema command conf vars</td>\n",
       "      <td>place any commands to setup tg2raptorized here</td>\n",
       "      <td>https://github.com/ralphbean/raptorizemw/blob/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ralphbean/raptorizemw</td>\n",
       "      <td>examples/tg2-raptorized/tg2raptorized/tests/mo...</td>\n",
       "      <td>setUp</td>\n",
       "      <td>25</td>\n",
       "      <td>def setUp(self):\\n    \"\"\"Prepare model test fi...</td>\n",
       "      <td>def setUp self try new_attrs new_attrs update ...</td>\n",
       "      <td>prepare model test fixture .</td>\n",
       "      <td>https://github.com/ralphbean/raptorizemw/blob/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ralphbean/raptorizemw</td>\n",
       "      <td>examples/tg2-raptorized/tg2raptorized/tests/mo...</td>\n",
       "      <td>tearDown</td>\n",
       "      <td>36</td>\n",
       "      <td>def tearDown(self):\\n    \"\"\"Finish model test ...</td>\n",
       "      <td>def tearDown self</td>\n",
       "      <td>finish model test fixture .</td>\n",
       "      <td>https://github.com/ralphbean/raptorizemw/blob/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nwo                                               path  \\\n",
       "0  ralphbean/raptorizemw  examples/tg2-raptorized/tg2raptorized/websetup...   \n",
       "1  ralphbean/raptorizemw  examples/tg2-raptorized/tg2raptorized/controll...   \n",
       "2  ralphbean/raptorizemw  examples/tg2-raptorized/tg2raptorized/websetup...   \n",
       "3  ralphbean/raptorizemw  examples/tg2-raptorized/tg2raptorized/tests/mo...   \n",
       "4  ralphbean/raptorizemw  examples/tg2-raptorized/tg2raptorized/tests/mo...   \n",
       "\n",
       "  function_name  lineno                                  original_function  \\\n",
       "0     bootstrap       8  def bootstrap(command, conf, vars):\\n    \"\"\"Pl...   \n",
       "1      document      21  @expose('tg2raptorized.templates.error')\\ndef ...   \n",
       "2  setup_schema       7  def setup_schema(command, conf, vars):\\n    \"\"...   \n",
       "3         setUp      25  def setUp(self):\\n    \"\"\"Prepare model test fi...   \n",
       "4      tearDown      36  def tearDown(self):\\n    \"\"\"Finish model test ...   \n",
       "\n",
       "                                     function_tokens  \\\n",
       "0                    def bootstrap command conf vars   \n",
       "1  expose tg2raptorized templates error def docum...   \n",
       "2                 def setup_schema command conf vars   \n",
       "3  def setUp self try new_attrs new_attrs update ...   \n",
       "4                                  def tearDown self   \n",
       "\n",
       "                                 docstring_tokens  \\\n",
       "0  place any commands to setup tg2raptorized here   \n",
       "1                       render the error document   \n",
       "2  place any commands to setup tg2raptorized here   \n",
       "3                    prepare model test fixture .   \n",
       "4                     finish model test fixture .   \n",
       "\n",
       "                                                 url  \n",
       "0  https://github.com/ralphbean/raptorizemw/blob/...  \n",
       "1  https://github.com/ralphbean/raptorizemw/blob/...  \n",
       "2  https://github.com/ralphbean/raptorizemw/blob/...  \n",
       "3  https://github.com/ralphbean/raptorizemw/blob/...  \n",
       "4  https://github.com/ralphbean/raptorizemw/blob/...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output each set to train/valid/test.function/docstrings/lineage files\n",
    "Original functions are also written to compressed json files. (Raw functions contain `,`, `\\t`, `\\n`, etc., it is less error-prone using json format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to(df, filename):\n",
    "    df.function_tokens.to_csv('{}.function'.format(filename), index=False)\n",
    "    df.original_function.to_json('{}_original_function.json.gz'.format(filename), orient='values', compression='gzip')\n",
    "    if filename != 'without_docstrings':\n",
    "        df.docstring_tokens.to_csv('{}.docstring'.format(filename), index=False)\n",
    "    df.url.to_csv('{}.lineage'.format(filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to output files\n",
    "write_to(train, 'train')\n",
    "write_to(valid, 'valid')\n",
    "write_to(test, 'test')\n",
    "write_to(without_docstrings, 'without_docstrings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root  12M May 20 02:30 test.docstring\r\n",
      "-rw-r--r-- 1 root root  52M May 20 02:29 test.function\r\n",
      "-rw-r--r-- 1 root root  15M May 20 02:30 test.lineage\r\n",
      "-rw-r--r-- 1 root root  77M May 20 02:29 train.docstring\r\n",
      "-rw-r--r-- 1 root root 338M May 20 02:27 train.function\r\n",
      "-rw-r--r-- 1 root root  96M May 20 02:29 train.lineage\r\n",
      "-rw-r--r-- 1 root root  13M May 20 02:29 valid.docstring\r\n",
      "-rw-r--r-- 1 root root  56M May 20 02:29 valid.function\r\n",
      "-rw-r--r-- 1 root root  16M May 20 02:29 valid.lineage\r\n",
      "-rw-r--r-- 1 root root 1.1G May 20 02:30 without_docstrings.function\r\n",
      "-rw-r--r-- 1 root root 342M May 20 02:34 without_docstrings.lineage\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah | grep -E '*.function$|*.docstring$|*.lineage$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pre-processed data is also hosted on Google Cloud, at the following URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/test.docstring\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/test.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/test.lineage\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/train.docstring\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/train.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/train.lineage\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.docstring\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.lineage\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.lineage\n"
     ]
    }
   ],
   "source": [
    "# cool trick to send shell commands into a python variable in a jupyter notebook!\n",
    "files = ! ls | grep -E '*.function$|*.docstring$|*.lineage$'\n",
    "\n",
    "# print the urls\n",
    "urls = [f'https://storage.googleapis.com/kubeflow-examples/code_search/data/{f}' for f in files]\n",
    "for s in urls:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
